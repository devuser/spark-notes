sparknotes
==========

Note anything during writing spark or scala python php golang gopher bigdata hadoop review 大数据 面试 面试题 大数据面试题 作者在Github的博客列表 

- [Spark 笔记](http://devuser.github.io/spark-notes) 

- [Docker 笔记](http://devuser.github.io/docker-notes) 

- [Golang 笔记](http://devuser.github.io/golang-notes)

[从源代码开始](stepbystepfromsrc.md)

[PowerDesigner](powerdesigner.md)

[SPARK解决BAT问题](spark-bat.md)

[编写第一个Spark程序](case1_wordcount.md)

[机器学习](MLlib.md)

[推荐在豆瓣](recommenddation_in_douban.md)

[Python 00-01](django-leaning/ch00-enviroment/ch00-01.md)

[Python 00-02](django-leaning/ch00-enviroment/ch00-02.md)

[Python 00-03](django-leaning/ch00-enviroment/ch00-03-docker-readme.md)

[Python 00-04](django-leaning/ch00-enviroment/ch00-04-zsh-readme.md)



本系列文档基于`Spark 1.5-Hadoop 2.6`撰写。

如果没有特殊声明，文档中案例在`Cent OS 6.X`系列下为准， 其他操作系统请参考。

![bigdatareview_mindmap.png](http://www.i5life.com:8090/spark-notes/images/bigdatareview_mindmap.png)

大数据工程师面试题
==================

阅读指南
--------

-	下文的算法和模型两个词经常混用
-	很多技术问题可能没有标准答案，但是需要描述自己的关注点，或自己的理解
-	鼓励表达一些倾向性的观点，或一些基于实践的观点

Java部分
--------

1.	Java内存垃圾收集器是怎么工作的？
2.	Java内存分为哪几个区域？相互之间是如何转化地？
3.	Java 1.7和1.8有什么改变呢？
4.	HashMap和HashTable有什么区别？
5.	请说一下你对Java关键字 `synchronized` 的理解，如果你不懂Java语言的话，也请尝试说说你对 `synchronized` 的理解
6.	Java为什么会推出Java `NIO`（New I/O），在 `NIO`中有哪几个核心对象（缓冲区 `Buffer`、通道`Channel`、选择器`Selector`\)
7.	如果Java源代码显示调用内存回收，将会发生什么？
8.	Windows 32位机器上Java内存具有什么特征？
9.	Java项目不进行任何调整，直接从32位机器Java虚拟机迁移到64位机器Java虚拟机，速度会提升吗？

```
在Java1.4之前的I/O系统中，提供的都是面向流的I/O系统，系统一次一个字节地处理数据，
一个输入流产生一个字节的数据，一个输出流消费一个字节的数据，面向流的I/O速度非常慢，
而在Java 1.4中推出了NIO，这是一个面向块的I/O系统，系统以块的方式处理处理，
每一个操作在一步中产生或者消费一个数据库，按块处理要比按字节处理数据快的多。
在NIO中有几个核心对象需要掌握：缓冲区（Buffer）、通道（Channel）、选择器（Selector）。
```

大数据部分
----------

1.	MongoDB和Hadoop有什么区别？是同类型的产品吗？
2.	如果我告诉你Hadoop已经是大数据领域的事实标准，那么你分析哪几个方面帮助Hadoop成为事实标准呢？
3.	请描述你理解的数据仓库
4.	数据仓库和大数据有什么区别？
5.	数据集市和数据仓库有什么区别？
6.	数据集市一定不可以接受吗？为什么不可以接受？
7.	大数据技术除了Hadoop流派之外，还有哪些流派？
8.	Spark和Hadoop的区别？在大数据技术体系中各自扮演什么角色？
9.	Spark有哪些组成部分，Spark的架构基础是什么，或基于什么模型构建的？
10.	你知道大数据有哪些数据来源，各自有什么流行的工具？
11.	说说你大数据知识的来源
	-	国内流行的大数据书籍
	-	希望获得你热衷从官网获取新知
	-	观念更新大于知识贮备
	-	知识获取大于知识继承（强调外语和自学习能力）

数据分析
--------

1.	你了解机器学习吗？
2.	请讲述你了解或熟知的机器学习算法？
3.	数据采集环节经常遇到哪几类问题？说说自己对这几类问题的理解
4.	Spark和SPSS的区别？说说各自擅长的领域？
5.	Excel可以实现哪些数据分析呢？
6.	你了解R语言，R语言可以完成什么类型的任务？
7.	数据抽样有哪些注意事项？如果我们有30万左右的样本，那么需要抽取多少呢？
8.	数据抽样或统计学实验有哪几个评价指标？请描述一到两个案例来说明评价指标

场景分析
--------

1.	说说你对我们公司的理解？
2.	根据你的了解，我们公司的产品具有哪些特征？
3.	我们主要的客户群体是什么？怎么描述我们的客户群体？
4.	如果你作为VP的话，你会怎么细分我们的客户群体？
5.	如果强迫你规划未来18个月的依托大数据技术的产品，你会怎么规划我们的产品线呢？

一般项目经历
------------

1.	介绍你过去成功或参与度较高的项目经历，在里面担负的角色
2.	在过去的项目经历中，请描述3个案例来证明你的技术能力很强
3.	在过去的项目经历中，请描述3个应急场景证明你的技术能力很强
4.	如果给你三分钟来介绍自己，那么你愿意介绍自己的哪几个方面的优秀特征呢？
5.	难道仅仅认为自己在技术领域是优秀的？（秒杀技术控，面试官希望看到你的综合能力）

大数据项目经历
--------------

1.	你曾经参与或主导过哪些大数据类型的项目？项目目标是什么？你具体担负的哪个角色？ 使用哪些算法？
2.	使用哪些统计方法？
3.	如果解决用户商品匹配的话，你会采用什么类型的模型？ 二部图模型有什么缺陷？对应有什么改进模型？
4.	标签系统有什么特征？有什么问题？
5.	用户行为分析有什么模型？
6.	说说你曾经项目中的模型迭代过程？
7.	成功的大数据项目具有哪些特征？
8.	你认为大数据技术包括哪些组成部分？
9.	你认为大数据项目成功的关键是什么？
10.	大数据和企业内外哪些部门关联比较密切？
11.	你过去项目的SLA包涵哪些指标？
12.	如果你参与到我们的大数据项目中，你愿意设计哪些SLA指标？
13.	Web或移动端的时代，我们有哪些数据采集的方法？（如果能够说出来GA最佳）
14.	针对Web或移动端，你认为可以设置哪些观测点？
15.	在原始数据采集的基础上，可以做哪些指标呢？
16.	如果从观察点提取出来50个观测指标，那么你在向高层汇报前你做哪些准备工作呢？ （基础指标的基础上，你需要继续抽象，或分解为若干个领域，或绘制曲线）
17.	周日晚上接到高层的电话通知，周一早晨9点半参加一个**重要会议**。该重要会有由公司内外部的重要人士参加。要求你在会议上介绍你主导的大数据项目工作。然后你会做什么？

```
- 有哪些类型的人士参加？如果能够具体到名字最佳？
- 各自的诉求是什么？
- 会议的召集者希望你表达什么？
- 会议分为哪几个阶段？
- 会议室大小？是否有投影设备？是否需要准备纸质件？
- 如果说自己立即去调试系统，或者准备PPT，那么是完败
```

语言选择
--------

1.	你熟知哪些开发语言或工具类软件？
2.	你写日记吗？如果不写日记的话，你采用哪些工具或方式来记录自己的知识呢？
3.	你了解PHP、Python吗？说说你对这两门语言的理解
4.	你知道哪些JavaScript前端技术框架？特点是什么？
5.	如果因项目需要，你愿意介绍并且主动学习一门开发语言或工具吗？
6.	说说你曾经快速学习一门开发语言的经历？

职业生涯
--------

1.	你愿意成为不参与底层代码的算法专家吗？或模型工程师？
2.	你认为大数据领域有哪些发展方向？五年或十年后你愿意成为哪个角色？
3.	参与大数据项目，你认为哪些是关键干系人？
4.	如果让你领导一个大数据项目，你认为分解为几个阶段？
5.	你怎么向公司高层介绍或请求发起一个大数据项目？
6.	你怎么解决大数据项目和公司现有业务系统的关系？
7.	大数据项目和各种日志分析系统间有什么区别？
8.	你怎么面向公众或无关者，比如记者、你的家人、你的私人朋友介绍你主导的大数据项目？

新员工
------

-	新员工报道第一天，你准备作什么？

```
  - 关键词新员工手册，强调过程资产
  - 按照新员工手册走完全程
  - 确保实现最基本的工作环境
  - 总结记录自己遇到的问题，并尝试更新新员工手册
```

-	你怎么规划自己入职第一周的工作？

```
    - 谁是你的主管，多数情况下入职前就认识了 和主管一起沟通你的职业规划和工作规划
    - 你业务范围内的关联部门？拜访关联部门领导
    - 人事、财务、行政 - 你主要的客户群体？或主要的客户？
    - 你怎么规划自己入职前3个月的工作？
```

-	如果要求你做为公司的大数据培训讲师，你愿意和受众分享哪三条经验或心得呢？

关于修订
--------

上述面试题目，是我作为面试官或求职者而总结的，不足之处，敬请修订。 也可以邮件给我。

提醒读者，直接针对题目的准备是无用的，鼓励对题目背后的领域进行深入的了解。 请正确的方式的来阅读本文。

支持邮箱: pythoner@icloud.com

```
大数据工程师面试题到此结束
```

Spark Step by Step
==================

幸福生活从Docker开始
--------------------

在DockerHub搜索Spark `docker search -s 2 spark`

存在若干个Spark镜像，推荐选择 _ sequenceiq/spark _ 执行如下命令拉取 ｀docker pull sequenceiq/spark\`

有强迫症的同学建议执行如下命令拉取该镜像的所有版本

`docker pull -a sequenceiq/spark`

拉取所有的版本是有意义的，因为Spark处在快速成长期，年初到现在从_ 1.2 _ 版本迭代到_ 1.5 \_

目前市面上流行的印刷品的书，多数还是基于_ 1.2 _ 版本。 作为初学者来说，遇到版本差异，会非常痛苦。

所以我建议，使用与您印刷品的书一致的Spark版本。

**机器学习框架（Spark MLlib)**
==============================

目前支持4种常见的机器学习问题：二元分类、回归、聚类以及协同过滤 - 依赖 （将会调用jblas线性代数库，这个库本身依赖于原生的Fortran程序 如果想用Python调用MLlib，需要安装NumPy 1.7或更新的版本 - 二元分类

```
是个监督学习问题。 目前支持两个适用于二元分类的标准模型家族：线性支持向量机（SVMs）和逻辑回归， 同时也分别适用于这两个模型家族的L1和L2正则化变体。

这些训练算法都利用了一个底层的梯度下降基础算法。 二元分类算法的输入值是一个正则项参数（regParam）和多个与梯度下降相关的参数（stepSize，numIterations，miniBatchFraction）

目前可用的二元分类算法：
- **SVMWithSGD**
- **LogisticRegressWithSGD**
```

-	线性回归
-	聚类
-	协同过滤 隐性反馈与协同反馈
-	梯度下降基础算法
-	二元分类
-	线性回归
-	聚类
-	协同过滤

搭建Hadoop单机版本和伪分布式开发环境
====================================

`sudo -s`进入**root**用户权限模式

`apt-get install vim`

Hadoop是采用SSH进行通讯的，此时要设置密码为空， 即不需要密码登录，这样免去每次通讯时都输入密码。

`apt-get install ssh`

安装完毕后启动SSH服务

`/etc/init.d/ssh start`

以下命令验证服务是否正常启动

`ps -e|grep ssh`

如下命令产生私钥和公钥

`ssh-keygen -t rsa -P ""`

使用Java自带的jps命令查询出所有的守护进程:

\** @todo插入图片\** - 创建HDFS的文件夹*/input* `bin/hadoop dfs -mkdir /input` - 复制本地的配置文件到HDFS文件夹_/input* `bin/hadoop dfs -copyFromLocal etc/hadoop/_.xml /input`- 在刚刚构建的伪分布式模式下运行自带的_wordcount_程序`bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar wordcount /input /output`

开始第一个测试案例
==================

-	启动Spark集群的Mater `$SPARK_HOME/sbin/start-master.sh`
-	启动Spark集群的Slaves `$SPARK_HOME/sbin/start-slaves.sh`
-	启动Hadoop集群`/data/hadoop/sbin/start-all.sh`

`hadoop dfs -copyFromLocal ./README.md /`

`val file = sc.textFile("hdfs://inside-bigdata04:9000/README.md")`

`file.filter(line => line.contains("Spark"))`

查看HDFS的文件或文件夹
----------------------

-	`hadoop dfs -get  hdfs://10.104.19.122:9000/foo.md`
-	查看文件末尾的若干行 `hadoop dfs -tail -f hdfs://10.104.19.122:9000/README.md`
-	列举HDFS的文件或文件夹 `hadoop dfs -ls  hdfs://10.104.19.122:9000/`

目前推荐如下命令

`hdfs dfs -ls /`

下面给出在Hadoop 2.6版本的命令组合 - 列举远程hdfs的文件或文件夹 `hdfs dfs -ls  hdfs://$HADOOP_MASTER_ID:9000/` - 删除hdfs的文件夹 `hdfs dfs -ls hdfs://$HADOOP_MASTER_ID:9000/XXXX.csv`

SBT
===

##名字的由来

类似yum一样，始终致力于发明新的轮子，每个轮子都说自己在解决前辈不能解决的问题。 或者比前辈更佳高校。 SBT，我实际使用过程中，发现 - 从语法或使用习惯来说，更加匹配Scala - 用类似编程语言的方式书写，胜过XML - 包的管理更高效，兼容Maven

在打包前，偶尔发生未能跟踪最新修改的情况， 也就说希望每次打包使用如下命令组合

```
sbt clean compile package
```

如果简单使用`sbt package`可能没应用最新的源代码或包依赖关系。
