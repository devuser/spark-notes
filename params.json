{"name":"Spark-notes","tagline":"Note anything during writing spark or scala hadoop golfing gopher python review 大数据 面试题 面试 BAT","body":"# sparknotes\r\nNote anything during writing spark or scala python php golang gopher bigdata hadoop review 大数据 面试 面试题 大数据面试题 作者在Github的博客列表\r\n- [Spark 笔记](http://devuser.github.io/spark-notes)\r\n- [Docker 笔记](http://devuser.github.io/docker-notes)\r\n- [Golang 笔记](http://devuser.github.io/golang-notes)\r\n\r\n[从源代码开始](stepbystepfromsrc.md)\r\n\r\n[PowerDesigner](powerdesigner.md)\r\n\r\n[SPARK解决BAT问题](spark-bat.md)\r\n\r\n[编写第一个Spark程序](case1_wordcount.md)\r\n\r\n[机器学习](MLlib.md)\r\n\r\n[推荐在豆瓣](recommenddation_in_douban.md)\r\n\r\n本系列文档基于`Spark 1.5-Hadoop 2.6`撰写。\r\n\r\n如果没有特殊声明，文档中案例在`Cent OS 6.X`系列下为准， 其他操作系统请参考。\r\n\r\n![bigdatareview_mindmap.png](http://www.i5life.com:8090/spark-notes/images/bigdatareview_mindmap.png)\r\n\r\n# 大数据工程师面试题\r\n## 阅读指南\r\n- 下文的算法和模型两个词经常混用\r\n- 很多技术问题可能没有标准答案，但是需要描述自己的关注点，或自己的理解\r\n- 鼓励表达一些倾向性的观点，或一些基于实践的观点\r\n\r\n## Java部分\r\n1. Java内存垃圾收集器是怎么工作的？\r\n2. Java内存分为哪几个区域？相互之间是如何转化地？\r\n3. Java 1.7和1.8有什么改变呢？\r\n4. HashMap和HashTable有什么区别？\r\n5. 请说一下你对Java关键字 `synchronized` 的理解，如果你不懂Java语言的话，也请尝试说说你对 `synchronized` 的理解\r\n6. Java为什么会推出Java `NIO`（New I/O），在 `NIO`中有哪几个核心对象（缓冲区 `Buffer`、通道`Channel`、选择器`Selector`)\r\n7. 如果Java源代码显示调用内存回收，将会发生什么？\r\n8. Windows 32位机器上Java内存具有什么特征？\r\n9. Java项目不进行任何调整，直接从32位机器Java虚拟机迁移到64位机器Java虚拟机，速度会提升吗？\r\n\r\n```\r\n在Java1.4之前的I/O系统中，提供的都是面向流的I/O系统，系统一次一个字节地处理数据，\r\n一个输入流产生一个字节的数据，一个输出流消费一个字节的数据，面向流的I/O速度非常慢，\r\n而在Java 1.4中推出了NIO，这是一个面向块的I/O系统，系统以块的方式处理处理，\r\n每一个操作在一步中产生或者消费一个数据库，按块处理要比按字节处理数据快的多。\r\n在NIO中有几个核心对象需要掌握：缓冲区（Buffer）、通道（Channel）、选择器（Selector）。\r\n```\r\n\r\n## 大数据部分\r\n1. MongoDB和Hadoop有什么区别？是同类型的产品吗？\r\n2. 如果我告诉你Hadoop已经是大数据领域的事实标准，那么你分析哪几个方面帮助Hadoop成为事实标准呢？\r\n3. 请描述你理解的数据仓库\r\n4. 数据仓库和大数据有什么区别？\r\n5. 数据集市和数据仓库有什么区别？\r\n6. 数据集市一定不可以接受吗？为什么不可以接受？\r\n7. 大数据技术除了Hadoop流派之外，还有哪些流派？\r\n8. Spark和Hadoop的区别？在大数据技术体系中各自扮演什么角色？\r\n9. Spark有哪些组成部分，Spark的架构基础是什么，或基于什么模型构建的？\r\n10. 你知道大数据有哪些数据来源，各自有什么流行的工具？\r\n11. 说说你大数据知识的来源\r\n  - 国内流行的大数据书籍\r\n  - 希望获得你热衷从官网获取新知\r\n  - 观念更新大于知识贮备\r\n  - 知识获取大于知识继承（强调外语和自学习能力）\r\n\r\n## 数据分析\r\n1. 你了解机器学习吗？\r\n2. 请讲述你了解或熟知的机器学习算法？\r\n3. 数据采集环节经常遇到哪几类问题？说说自己对这几类问题的理解\r\n4. Spark和SPSS的区别？说说各自擅长的领域？\r\n5. Excel可以实现哪些数据分析呢？\r\n6. 你了解R语言，R语言可以完成什么类型的任务？\r\n7. 数据抽样有哪些注意事项？如果我们有30万左右的样本，那么需要抽取多少呢？\r\n8. 数据抽样或统计学实验有哪几个评价指标？请描述一到两个案例来说明评价指标\r\n\r\n## 场景分析\r\n1. 说说你对我们公司的理解？\r\n2. 根据你的了解，我们公司的产品具有哪些特征？\r\n3. 我们主要的客户群体是什么？怎么描述我们的客户群体？\r\n4. 如果你作为VP的话，你会怎么细分我们的客户群体？\r\n5. 如果强迫你规划未来18个月的依托大数据技术的产品，你会怎么规划我们的产品线呢？\r\n\r\n## 一般项目经历\r\n1. 介绍你过去成功或参与度较高的项目经历，在里面担负的角色\r\n2. 在过去的项目经历中，请描述3个案例来证明你的技术能力很强\r\n3. 在过去的项目经历中，请描述3个应急场景证明你的技术能力很强\r\n4. 如果给你三分钟来介绍自己，那么你愿意介绍自己的哪几个方面的优秀特征呢？\r\n5. 难道仅仅认为自己在技术领域是优秀的？（秒杀技术控，面试官希望看到你的综合能力）\r\n\r\n## 大数据项目经历\r\n1. 你曾经参与或主导过哪些大数据类型的项目？项目目标是什么？你具体担负的哪个角色？ 使用哪些算法？\r\n2. 使用哪些统计方法？\r\n3. 如果解决用户商品匹配的话，你会采用什么类型的模型？ 二部图模型有什么缺陷？对应有什么改进模型？\r\n4. 标签系统有什么特征？有什么问题？\r\n5. 用户行为分析有什么模型？\r\n6. 说说你曾经项目中的模型迭代过程？\r\n7. 成功的大数据项目具有哪些特征？\r\n8. 你认为大数据技术包括哪些组成部分？\r\n9. 你认为大数据项目成功的关键是什么？\r\n10. 大数据和企业内外哪些部门关联比较密切？\r\n11. 你过去项目的SLA包涵哪些指标？\r\n12. 如果你参与到我们的大数据项目中，你愿意设计哪些SLA指标？\r\n13. Web或移动端的时代，我们有哪些数据采集的方法？（如果能够说出来GA最佳）\r\n14. 针对Web或移动端，你认为可以设置哪些观测点？\r\n15. 在原始数据采集的基础上，可以做哪些指标呢？\r\n16. 如果从观察点提取出来50个观测指标，那么你在向高层汇报前你做哪些准备工作呢？ （基础指标的基础上，你需要继续抽象，或分解为若干个领域，或绘制曲线）\r\n17. 周日晚上接到高层的电话通知，周一早晨9点半参加一个**重要会议**。该重要会有由公司内外部的重要人士参加。要求你在会议上介绍你主导的大数据项目工作。然后你会做什么？\r\n\r\n```\r\n- 有哪些类型的人士参加？如果能够具体到名字最佳？\r\n- 各自的诉求是什么？\r\n- 会议的召集者希望你表达什么？\r\n- 会议分为哪几个阶段？\r\n- 会议室大小？是否有投影设备？是否需要准备纸质件？\r\n- 如果说自己立即去调试系统，或者准备PPT，那么是完败\r\n```\r\n\r\n## 语言选择\r\n1. 你熟知哪些开发语言或工具类软件？\r\n2. 你写日记吗？如果不写日记的话，你采用哪些工具或方式来记录自己的知识呢？\r\n3. 你了解PHP、Python吗？说说你对这两门语言的理解\r\n4. 你知道哪些JavaScript前端技术框架？特点是什么？\r\n5. 如果因项目需要，你愿意介绍并且主动学习一门开发语言或工具吗？\r\n6. 说说你曾经快速学习一门开发语言的经历？\r\n\r\n## 职业生涯\r\n1. 你愿意成为不参与底层代码的算法专家吗？或模型工程师？\r\n2. 你认为大数据领域有哪些发展方向？五年或十年后你愿意成为哪个角色？\r\n3. 参与大数据项目，你认为哪些是关键干系人？\r\n4. 如果让你领导一个大数据项目，你认为分解为几个阶段？\r\n5. 你怎么向公司高层介绍或请求发起一个大数据项目？\r\n6. 你怎么解决大数据项目和公司现有业务系统的关系？\r\n7. 大数据项目和各种日志分析系统间有什么区别？\r\n8. 你怎么面向公众或无关者，比如记者、你的家人、你的私人朋友介绍你主导的大数据项目？\r\n\r\n## 新员工\r\n- 新员工报道第一天，你准备作什么？\r\n\r\n```\r\n  - 关键词新员工手册，强调过程资产\r\n  - 按照新员工手册走完全程\r\n  - 确保实现最基本的工作环境\r\n  - 总结记录自己遇到的问题，并尝试更新新员工手册\r\n```\r\n\r\n- 你怎么规划自己入职第一周的工作？\r\n\r\n```\r\n    - 谁是你的主管，多数情况下入职前就认识了 和主管一起沟通你的职业规划和工作规划\r\n    - 你业务范围内的关联部门？拜访关联部门领导\r\n    - 人事、财务、行政 - 你主要的客户群体？或主要的客户？\r\n    - 你怎么规划自己入职前3个月的工作？\r\n```\r\n\r\n- 如果要求你做为公司的大数据培训讲师，你愿意和受众分享哪三条经验或心得呢？\r\n\r\n## 关于修订\r\n上述面试题目，是我作为面试官或求职者而总结的，不足之处，敬请修订。 也可以邮件给我。\r\n\r\n提醒读者，直接针对题目的准备是无用的，鼓励对题目背后的领域进行深入的了解。 请正确的方式的来阅读本文。\r\n\r\n支持邮箱: pythoner@icloud.com\r\n\r\n```\r\n大数据工程师面试题到此结束\r\n```\r\n\r\n# Spark Step by Step\r\n## 幸福生活从Docker开始\r\n在DockerHub搜索Spark `docker search -s 2 spark`\r\n\r\n存在若干个Spark镜像，推荐选择 _ sequenceiq/spark _ 执行如下命令拉取 ｀docker pull sequenceiq/spark`\r\n\r\n有强迫症的同学建议执行如下命令拉取该镜像的所有版本\r\n\r\n`docker pull -a sequenceiq/spark`\r\n\r\n拉取所有的版本是有意义的，因为Spark处在快速成长期，年初到现在从_ 1.2 _ 版本迭代到_ 1.5 _\r\n\r\n目前市面上流行的印刷品的书，多数还是基于_ 1.2 _ 版本。 作为初学者来说，遇到版本差异，会非常痛苦。\r\n\r\n所以我建议，使用与您印刷品的书一致的Spark版本。\r\n\r\n# **机器学习框架（Spark MLlib)**\r\n目前支持4种常见的机器学习问题：二元分类、回归、聚类以及协同过滤 - 依赖 （将会调用jblas线性代数库，这个库本身依赖于原生的Fortran程序 如果想用Python调用MLlib，需要安装NumPy 1.7或更新的版本 - 二元分类\r\n\r\n```\r\n是个监督学习问题。 目前支持两个适用于二元分类的标准模型家族：线性支持向量机（SVMs）和逻辑回归， 同时也分别适用于这两个模型家族的L1和L2正则化变体。\r\n\r\n这些训练算法都利用了一个底层的梯度下降基础算法。 二元分类算法的输入值是一个正则项参数（regParam）和多个与梯度下降相关的参数（stepSize，numIterations，miniBatchFraction）\r\n\r\n目前可用的二元分类算法：\r\n- **SVMWithSGD**\r\n- **LogisticRegressWithSGD**\r\n```\r\n\r\n- 线性回归\r\n- 聚类\r\n- 协同过滤 隐性反馈与协同反馈\r\n- 梯度下降基础算法\r\n- 二元分类\r\n- 线性回归\r\n- 聚类\r\n- 协同过滤\r\n\r\n# 搭建Hadoop单机版本和伪分布式开发环境\r\n`sudo -s`进入**root**用户权限模式\r\n\r\n`apt-get install vim`\r\n\r\nHadoop是采用SSH进行通讯的，此时要设置密码为空， 即不需要密码登录，这样免去每次通讯时都输入密码。\r\n\r\n`apt-get install ssh`\r\n\r\n安装完毕后启动SSH服务\r\n\r\n`/etc/init.d/ssh start`\r\n\r\n以下命令验证服务是否正常启动\r\n\r\n`ps -e|grep ssh`\r\n\r\n如下命令产生私钥和公钥\r\n\r\n`ssh-keygen -t rsa -P \"\"`\r\n\r\n使用Java自带的jps命令查询出所有的守护进程:\r\n\r\n** @todo插入图片** - 创建HDFS的文件夹_/input_ `bin/hadoop dfs -mkdir /input` - 复制本地的配置文件到HDFS文件夹_/input* `bin/hadoop dfs -copyFromLocal etc/hadoop/_.xml /input`- 在刚刚构建的伪分布式模式下运行自带的_wordcount_程序`bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar wordcount /input /output`\r\n\r\n# 开始第一个测试案例\r\n- 启动Spark集群的Mater `$SPARK_HOME/sbin/start-master.sh`\r\n- 启动Spark集群的Slaves `$SPARK_HOME/sbin/start-slaves.sh`\r\n- 启动Hadoop集群`/data/hadoop/sbin/start-all.sh`\r\n\r\n`hadoop dfs -copyFromLocal ./README.md /`\r\n\r\n`val file = sc.textFile(\"hdfs://inside-bigdata04:9000/README.md\")`\r\n\r\n`file.filter(line => line.contains(\"Spark\"))`\r\n\r\n## 查看HDFS的文件或文件夹\r\n- `hadoop dfs -get  hdfs://10.104.19.122:9000/foo.md`\r\n- 查看文件末尾的若干行 `hadoop dfs -tail -f hdfs://10.104.19.122:9000/README.md`\r\n- 列举HDFS的文件或文件夹 `hadoop dfs -ls  hdfs://10.104.19.122:9000/`\r\n\r\n目前推荐如下命令\r\n\r\n`hdfs dfs -ls /`\r\n\r\n`hdfs dfs -ls  hdfs://$HADOOP_MASTER_ID:9000/`\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}